{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "991dd280e1aa895006782f2420299f43c365bf3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from functools import reduce\n",
    "import random\n",
    "import re\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.tensor as tensor\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "243278ccda7ad7c9d6d4352f7fca1d44549d1084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1306122, 3); cols: ['qid', 'question_text', 'target']\n",
      "Test shape: (375806, 2); cols: ['qid', 'question_text']\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"../input\"\n",
    "TRAIN_CSV = f\"{DATA_DIR}/train.csv\"\n",
    "TEST_CSV = f\"{DATA_DIR}/test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}; cols: {list(train_df.columns)}\")\n",
    "print(f\"Test shape: {test_df.shape}; cols: {list(test_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "b6390d234bfae617a0628e8d72329f5a212d1edb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sincere: 1225312 (93.813%); insincere: 80810 (6.187%); ratio (-/+): 15.163; ratio (+/-): 0.066\n",
      "\n",
      "sincere: Is Islam a good thing?\n",
      "\n",
      "insincere: What is the point of letting criminals that committed felonies back to the society? Why can't we simply lock them up like nuclear waste?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sincere = train_df.loc[train_df['target'] == 0]\n",
    "insincere = train_df.loc[train_df['target'] == 1]\n",
    "\n",
    "print(\n",
    "    f\"sincere: {len(sincere)} ({round(100.0 * len(sincere)/len(train_df), 3)}%); \"\n",
    "    f\"insincere: {len(insincere)} ({round(100.0 * len(insincere)/len(train_df), 3)}%); \"\n",
    "    f\"ratio (-/+): {round(len(sincere)/len(insincere), 3)}; \"\n",
    "    f\"ratio (+/-): {round(len(insincere)/len(sincere), 3)}\\n\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"sincere: {sincere.iloc[random.randint(0, len(sincere))]['question_text']}\\n\\n\"\n",
    "    f\"insincere: {insincere.iloc[random.randint(0, len(insincere))]['question_text']}\"\n",
    ")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_GLOVE_FILE = f\"{DATA_DIR}/embeddings/glove.840B.300d/glove.840B.300d.txt\"\n",
    "EMB_WORD2VEC_FILE = f\"{DATA_DIR}/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\"\n",
    "EMB_PARAGRAM_FILE = f\"{DATA_DIR}/embeddings/paragram_300_sl999/paragram_300_sl999.txt\"\n",
    "EMB_WIKI_FILE = f\"{DATA_DIR}/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_word2vec = KeyedVectors.load_word2vec_format(EMB_WORD2VEC_FILE, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emb_word2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6f796f4415b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{len(emb_word2vec.vocab)} x {emb_word2vec['the'].size}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xiaomi\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0memb_word2vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'emb_word2vec' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"{len(emb_word2vec.vocab)} x {emb_word2vec['the'].size}\")\n",
    "print(\"xiaomi\" in emb_word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wiki():\n",
    "    def get_coefs(word,*arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMB_WIKI_FILE) if len(o)>100)\n",
    "    \n",
    "    return embeddings_index\n",
    "\n",
    "emb_wiki = load_wiki()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999994 x 300\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(emb_wiki)} x {emb_wiki['the'].size}\")\n",
    "print(\"xiaomi\" in emb_wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove():\n",
    "    def get_coefs(word,*arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMB_GLOVE_FILE, encoding='latin'))\n",
    "        \n",
    "    return embeddings_index\n",
    "\n",
    "emb_glove = load_glove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2196016 x 300\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(emb_glove)} x {emb_glove['a'].size}\")\n",
    "print(\"xiaomi\" in emb_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ParaGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_paragram():\n",
    "    def get_coefs(word,*arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMB_PARAGRAM_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100)\n",
    "\n",
    "    return embeddings_index\n",
    "    \n",
    "emb_paragram = load_paragram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703755 x 300\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(emb_paragram)} x {emb_paragram['the'].size}\")\n",
    "print(\"paytm\" in emb_paragram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1253d44aae34b978cdbe694121acd3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a712a547234bdcbe837df3637a3f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2196016), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef886992cb84022928db38e5ef33443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1703755), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def combine_emb_dicts(*embs):\n",
    "    out_emb = defaultdict(lambda : np.zeros(300, dtype=np.float32))\n",
    "    \n",
    "    n = len(embs)\n",
    "    \n",
    "    for emb in tqdm(embs, total=n):\n",
    "        for w, e in tqdm(emb.items()):\n",
    "            out_emb[w] += (1.0/n) * e\n",
    "                \n",
    "    return out_emb\n",
    "            \n",
    "\n",
    "emb_glove_paragram = combine_emb_dicts(emb_glove, emb_paragram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emb_word2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-298449d847f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0m_w2v_not_glove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memb_word2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0memb_glove\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0m_w2v_not_glove\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'emb_word2vec' is not defined"
     ]
    }
   ],
   "source": [
    "_glove_not_w2v = Counter()\n",
    "_w2v_not_glove = Counter()\n",
    "\n",
    "for w in tqdm(emb_word2vec.vocab):\n",
    "    if w not in emb_glove:\n",
    "        _w2v_not_glove[w] += 1\n",
    "\n",
    "for w in tqdm(emb_glove):\n",
    "    if w not in emb_word2vec:\n",
    "        _glove_not_w2v[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"glove not w2v: {len(_glove_not_w2v)}; w2v not glove: {len(_w2v_not_glove)}\")\n",
    "print(\"-\" * 64)\n",
    "print(random.sample(set(_w2v_not_glove), 10))\n",
    "print(\"-\" * 64)\n",
    "print(random.sample(set(_glove_not_w2v), 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "0e6ac0681544ffa4ddf6af342222d80f9407fda3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PUNCTUATION = {\n",
    "    'sep'   : u'\\u200b' + \"/-'´′‘…—−–\",\n",
    "    'keep'  : \"&\",\n",
    "    'remove': '?!.,，\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~“”’™•°'\n",
    "}\n",
    "\n",
    "SYN_DICT = {\n",
    "    'cryptocurrencies': 'crypto currencies',\n",
    "    'ethereum'        : 'crypto currency',\n",
    "    'coinbase'        : 'crypto platform',\n",
    "    'altcoin'         : 'crypto currency',\n",
    "    'altcoins'        : 'crypto currency',\n",
    "    'litecoin'        : 'crypto currency',\n",
    "    'fortnite'        : 'video game',\n",
    "    'quorans'         : 'quora members',\n",
    "    'quoras'          : 'quora members',\n",
    "    'qoura'           : 'quora',\n",
    "    'brexit'          : 'britain exit',\n",
    "    'redmi'           : 'phone',\n",
    "    'oneplus'         : 'phone',\n",
    "    'hackerrank'      : 'programming challenges',\n",
    "    'bhakts'          : 'gullible',\n",
    "    '√'               : 'square root',\n",
    "    '÷'               : 'division',\n",
    "    '∞'               : 'infinity',\n",
    "    '€'               : 'euro',\n",
    "    '£'               : 'pound sterling',\n",
    "    '$'               : 'dollar',\n",
    "    '₹'               : 'rupee',\n",
    "    '×'               : 'product',\n",
    "    'ã'               : 'a',\n",
    "    'è'               : 'e',\n",
    "    'é'               : 'e',\n",
    "    'ö'               : 'o',\n",
    "    '²'               : 'squared',\n",
    "    '∈'               : 'in',\n",
    "    '∩'               : 'intersection',\n",
    "    u'\\u0398'         : 'Theta',\n",
    "    u'\\u03A0'         : 'Pi',\n",
    "    u'\\u03A9'         : 'Omega',\n",
    "    u'\\u0392'         : 'Beta',\n",
    "    u'\\u03B8'         : 'theta',\n",
    "    u'\\u03C0'         : 'pi',\n",
    "    u'\\u03C9'         : 'omega',\n",
    "    u'\\u03B2'         : 'beta',\n",
    "}\n",
    "\n",
    "\n",
    "def tokenize(s: str):\n",
    "    return list(map(lambda w: w.strip(), s.split()))\n",
    "\n",
    "\n",
    "def clean_text(x):\n",
    "    x = x.lower()\n",
    "\n",
    "    for p in PUNCTUATION['sep']:\n",
    "        x = x.replace(p, \" \")\n",
    "    for p in PUNCTUATION['keep']:\n",
    "        x = x.replace(p, f\" {p} \")\n",
    "    for p in PUNCTUATION['remove']:\n",
    "        x = x.replace(p, \"\")\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_site(x):\n",
    "    regex = re.compile('(www)([a-z0-9]+)(com|org)')\n",
    "    return regex.sub(lambda m: m.group(2), x)\n",
    "\n",
    "\n",
    "def clean_syn(x):\n",
    "    regex = re.compile('(%s)' % '|'.join(SYN_DICT.keys()))\n",
    "    return regex.sub(lambda m: SYN_DICT.get(m.group(0), ''), x)\n",
    "\n",
    "\n",
    "def clean_all(x):\n",
    "    x = clean_text(x)\n",
    "    x = clean_syn(x)\n",
    "    x = clean_site(x)\n",
    "    return x\n",
    "    \n",
    "\n",
    "def build_vocabulary(df: pd.DataFrame) -> Counter:\n",
    "    sentences = df.progress_apply(tokenize).values\n",
    "    vocab = Counter()\n",
    "    s_len = []\n",
    "    \n",
    "    for sentence in tqdm(sentences):  \n",
    "        s_len.append(len(sentence))\n",
    "        for word in sentence:\n",
    "            vocab[word] += 1\n",
    "    return vocab, np.array(s_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b024679d72402c9becd153da5fcf4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1306122), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5163a24d8794edcbc553d199acd2ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=375806), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97b826c5a8a4da89c51ebe28f46c25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1306122), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5985918f1fb488d8c3336231565f9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1306122), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd34d443c614a15a7ab8b0ed8631902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=375806), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ae9941fa154c0d89f80025a31c86e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=375806), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# clean\n",
    "train_df[\"clean_question_text\"] = train_df[\"question_text\"].progress_apply(clean_all)\n",
    "test_df[\"clean_question_text\"] = test_df[\"question_text\"].progress_apply(clean_all)\n",
    "\n",
    "# vocab\n",
    "train_vocab, train_s_len = build_vocabulary(train_df[\"clean_question_text\"])\n",
    "test_vocab, test_s_len = build_vocabulary(test_df[\"clean_question_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: DescribeResult(nobs=1306122, minmax=(0, 135), mean=12.985180557405817, variance=51.695601827754984, skewness=1.7884284249354365, kurtosis=4.158424002622946), median: 11.0\n",
      "test: DescribeResult(nobs=375806, minmax=(1, 87), mean=12.992267286844807, variance=51.59525692509565, skewness=1.7865806901779087, kurtosis=4.114102674231951), median: 11.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_train = scipy.stats.describe(train_s_len)\n",
    "d_test = scipy.stats.describe(test_s_len)\n",
    "print(f\"train: {d_train}, median: {np.median(train_s_len)}\")\n",
    "print(f\"test: {d_test}, median: {np.median(test_s_len)}\")\n",
    "\n",
    "nb = 60\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.hist(train_s_len, bins=nb, range=[0, 60], facecolor='red', label='train')\n",
    "\n",
    "plt.hist(test_s_len, bins=nb, range=[0, 60], facecolor='blue', label='test')\n",
    "plt.axvline(x=d_test.mean, color='cyan')\n",
    "\n",
    "plt.title(\"Sentence length\", size=24)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., prop={'size': 16})\n",
    "plt.xticks([5*i for i in range(14)])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_n = 20\n",
    "exclude = [\n",
    "    \"the\", \"of\", \"and\", \"to\", \"a\", \"in\", \"is\", \"i\",\n",
    "    \"that\", \"it\", \"for\", \"you\", \"was\", \"with\", \"on\",\n",
    "    \"as\", \"have\", \"but\", \"be\", \"they\"\n",
    "]\n",
    "\n",
    "for w in exclude:\n",
    "    del train_vocab[w]\n",
    "    del test_vocab[w]\n",
    "    \n",
    "Tmc = train_vocab.most_common()\n",
    "tmc = test_vocab.most_common()\n",
    "\n",
    "for i in range(_n):\n",
    "    print(f\"{Tmc[i]} -- {tmc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Less common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "Tmc = train_vocab.most_common()[:-n-1:-1]\n",
    "tmc = test_vocab.most_common()[:-n-1:-1]\n",
    "\n",
    "u = 0\n",
    "t = 10\n",
    "for w in train_vocab:\n",
    "    u += (train_vocab[w] <= t)\n",
    "print(f\"[train] {round(100.0 * u/len(train_vocab), 3)}% words have <= {t} occurences\")\n",
    "    \n",
    "u = 0\n",
    "t = 10\n",
    "for w in test_vocab:\n",
    "    u += (test_vocab[w] <= t)\n",
    "print(f\"[test]  {round(100.0 * u/len(train_vocab), 3)}% words have <= {t} occurences\")\n",
    "\n",
    "print()\n",
    "    \n",
    "for i in range(n):\n",
    "    print(f\"{Tmc[i]} -- {tmc[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_not_in_train = Counter()\n",
    "train_not_in_test = Counter()\n",
    "\n",
    "for w in test_vocab:\n",
    "    if w not in train_vocab:\n",
    "        test_not_in_train[w] += 1\n",
    "\n",
    "for w in train_vocab:\n",
    "    if w not in test_vocab:\n",
    "        train_not_in_test[w] += 1\n",
    "        \n",
    "train_uniq_words = set(train_vocab.keys())\n",
    "test_uniq_words = set(test_vocab.keys())\n",
    "uniq_words = set(train_uniq_words.union(test_uniq_words))\n",
    "all_oov = Counter()\n",
    "\n",
    "for w in uniq_words:\n",
    "    if w not in emb_glove:\n",
    "        all_oov[w] += 1\n",
    "        \n",
    "print(f\"train not in test: {len(train_not_in_test)}\")\n",
    "print(f\"test not in train: {len(test_not_in_train)}\")\n",
    "print(f\"train uniq: {len(train_uniq_words)}\")\n",
    "print(f\"test uniq: {len(test_uniq_words)}\")\n",
    "print(f\"total uniq words: {len(uniq_words)}\")\n",
    "\n",
    "# all_oov.most_common(10)\n",
    "\",\".join([x for (x, _) in test_not_in_train.most_common(50)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle misspellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleMisspellings:\n",
    "\n",
    "    def __init__(self, all_words_set, words2idx):\n",
    "        self.all_words_set = all_words_set\n",
    "        self.words2idx = words2idx\n",
    "\n",
    "    def prob(self, word):\n",
    "        return self.words2idx.get(word, 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def one_edit(word):\n",
    "        letters = string.ascii_lowercase\n",
    "\n",
    "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "        deletes = [L + R[1:] for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "        replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "        inserts = [L + c + R for L, R in splits for c in letters]\n",
    "\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "    def known(self, words):\n",
    "        return set(words).intersection(self.all_words_set)\n",
    "\n",
    "    def candidates(self, word):\n",
    "        return self.known([word]).union(self.known(self.one_edit(word)))\n",
    "\n",
    "    def correct(self, word):\n",
    "        cs = self.candidates(word)\n",
    "        return word if len(cs) == 0 else min(cs, key=lambda w: self.prob(w))\n",
    "\n",
    "misspelling_handler = HandleMisspellings(\n",
    "    all_words_set=set(list(emb_glove_paragram.keys())),\n",
    "    words2idx={w: i for (i, w) in enumerate(emb_glove_paragram.keys())}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'danger'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "t = 0\n",
    "misspelling_handler.correct('dang3r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embbedding coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_vocab_coverage(vocab, emb) -> (Counter, Counter):\n",
    "    oov = Counter() # out-of-vocab\n",
    "    inv = Counter() # in-vocab\n",
    "    oov_uniq_num = inv_uniq_num = 0.0\n",
    "    oov_all_num = inv_all_num = 0.0\n",
    "    \n",
    "    for w in tqdm(vocab):\n",
    "        if w in emb or misspelling_handler.correction(w) in emb:\n",
    "            inv[w] = vocab[w]\n",
    "            inv_uniq_num += 1\n",
    "            inv_all_num += vocab[w]\n",
    "        else:\n",
    "            oov[w] = vocab[w]\n",
    "            oov_uniq_num += 1\n",
    "            oov_all_num += vocab[w]\n",
    "    \n",
    "    cov_uniq = 100.0 * round(inv_uniq_num / len(vocab), 5)\n",
    "    cov_all = 100.0 * round(inv_all_num / (inv_all_num + oov_all_num), 5)\n",
    "    \n",
    "    print(f\"oov_uniq: {oov_uniq_num}; inv_uniq: {inv_uniq_num}; vocab_size: {len(vocab)}\")\n",
    "    print(\"embeddings-vocabulary coverage (unique): %.3f%%\" % cov_uniq)\n",
    "    print(\"embeddings-vocabulary coverage (all text): %.3f%%\" % cov_all)\n",
    "    \n",
    "    return oov, inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6955e8a16b4f8fb4a8efd95345fe5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=207016), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "oov_uniq: 25281.0; inv_uniq: 181735.0; vocab_size: 207016\n",
      "embeddings-vocabulary coverage (unique): 87.788%\n",
      "embeddings-vocabulary coverage (all text): 99.814%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'adityanath(106),alshamsi(92),unacademy(86),zerodha(80),tensorflow(73),doklam(70),lnmiit(68),kavalireddi(58),sgsits(40),nanodegree(38),gurugram(38),mhtcet(38),microservices(36),clickbait(33),lbsnaa(33),chromecast(31),naukricom(31),quoracom(29),demonitisation(29),bookingcom(29),bitconnect(28),deepmind(28),jungkook(28),trumpcare(27),wannacry(26),xxxtentacion(26),freelancercom(25),onedrive(25),codeforces(24),arrowverse(24),electroneum(24),sterling1000(23),genderfluid(23),internshala(22),chapterwise(22),igdtuw(22),ravindrababu(22),twinflame(22),padmaavat(21),tissnet(21),undergraduation(21),wordpresscom(21),hackerearth(21),veerwal(20),wikitribune(19),dhinchak(19),pizzagate(18),theranos(18),covfefe(18),yourquote(17)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov, inv = get_emb_vocab_coverage(train_vocab, emb_glove_paragram)\n",
    "\",\".join([x + f\"({y})\" for (x, y) in oov.most_common(50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9db18db43fc47658a6683b17cbbd70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105781), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "oov_uniq: 7904.0; inv_uniq: 97877.0; vocab_size: 105781\n",
      "embeddings-vocabulary coverage (unique): 92.528%\n",
      "embeddings-vocabulary coverage (all text): 99.815%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'alshamsi(31),tensorflow(29),unacademy(27),adityanath(26),lnmiit(23),zerodha(20),chromecast(19),kavalireddi(16),lbsnaa(14),gurugram(11)'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov, inv = get_emb_vocab_coverage(test_vocab, emb_paragram)\n",
    "\",\".join([x + f\"({y})\" for (x, y) in oov.most_common(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emb_wiki' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-a403a371af83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moov_thrd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moov\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moov_thrd\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0memb_wiki\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-40-a403a371af83>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moov_thrd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moov\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moov_thrd\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0memb_wiki\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'emb_wiki' is not defined"
     ]
    }
   ],
   "source": [
    "oov_thrd = [x for (x, y) in oov.most_common() if y > 0]\n",
    "len([w for w in oov_thrd if w in emb_wiki])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim, step_dim, with_bias=False):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.with_bias = with_bias\n",
    "        self.feature_dim = feature_dim\n",
    "        self.step_dim = step_dim\n",
    "\n",
    "        weight = torch.zeros(feature_dim, 1)\n",
    "        nn.init.xavier_uniform_(weight)\n",
    "        self.weight = nn.Parameter(weight, requires_grad=True)\n",
    "\n",
    "        if with_bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(step_dim), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature_dim = self.feature_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = torch.mm(\n",
    "            x.contiguous().view(-1, feature_dim), # (B * step_dim) x feature_dim\n",
    "            self.weight                           # feature_dim x 1\n",
    "        ).view(-1, step_dim)\n",
    "\n",
    "        if self.with_bias:\n",
    "            eij = eij + self.bias\n",
    "\n",
    "        eij = torch.tanh(eij)\n",
    "        # B x step_dim\n",
    "\n",
    "        a = torch.exp(eij)\n",
    "        a = a / (torch.sum(a, dim=1, keepdim=True) + 1e-10)\n",
    "        # B x step_dim\n",
    "\n",
    "        weighted_input = x * torch.unsqueeze(a, -1)\n",
    "        # B x step_dim x feature_dim\n",
    "        \n",
    "        # sum over step_dim\n",
    "        return torch.sum(weighted_input, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 140])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Attention(2*70, 70, True)\n",
    "x = torch.zeros((5, 70, 2*70))\n",
    "y = a(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, emb_matrix, hidden_size):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        num_words, emb_size = emb_matrix.shape\n",
    "\n",
    "        # sentence maxlen\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(num_words, emb_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(emb_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "\n",
    "        self.bidir_lstm1 = nn.LSTM(\n",
    "            input_size=emb_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.lstm1_attention = Attention(\n",
    "            feature_dim=2 * self.hidden_size, step_dim=self.hidden_size, with_bias=True\n",
    "        )\n",
    "\n",
    "        self.bidir_lstm2 = nn.LSTM(\n",
    "            input_size=2 * self.hidden_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.lstm2_attention = Attention(\n",
    "            feature_dim=2 * self.hidden_size, step_dim=self.hidden_size, with_bias=True\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(4 * 2 * self.hidden_size, 2 * self.hidden_size)\n",
    "        self.fc2 = nn.Linear(2 * self.hidden_size, 1)\n",
    "        \n",
    "        nn.init.orthogonal_(self.fc1.weight)\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "\n",
    "        self.dropout_emb = nn.Dropout2d(0.1)\n",
    "        self.dropout_rnn = nn.Dropout(0.4)\n",
    "        self.dropout_fc = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: B x sen_maxlen\n",
    "\n",
    "        emb = self.dropout_emb(self.embedding(x))\n",
    "        # B x sen_maxlen x emb_size\n",
    "\n",
    "        out_lstm1, _ = self.bidir_lstm1(emb)\n",
    "        # B x sen_maxlen x (2*sen_maxlen)\n",
    "\n",
    "        out_lstm1_atn = self.lstm1_attention(out_lstm1)\n",
    "        # B x (2*sen_maxlen)\n",
    "\n",
    "        out_lstm2, _ = self.bidir_lstm2(self.dropout_rnn(out_lstm1))\n",
    "        # B x sen_maxlen x (2*sen_maxlen)\n",
    "\n",
    "        out_lstm2_atn = self.lstm2_attention(out_lstm2)\n",
    "        # B x (2*sen_maxlen)\n",
    "\n",
    "        # pooling\n",
    "        max_pool, _ = torch.max(out_lstm2, dim=1)\n",
    "        # B x (2*sen_maxlen)\n",
    "        avg_pool = torch.mean(out_lstm2, dim=1)\n",
    "        # B x (2*sen_maxlen)\n",
    "\n",
    "        # concatenate results\n",
    "        out = torch.cat((out_lstm1_atn, out_lstm2_atn, max_pool, avg_pool), dim=1)\n",
    "        # B x (4 * 2*sen_maxlen)\n",
    "\n",
    "        out = self.fc2(self.dropout_fc(self.relu(self.fc1(out)))).unsqueeze(0)\n",
    "        # 1 x B x 1\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 5\n",
    "x = torch.zeros((bs, 70), dtype=torch.long)\n",
    "m = Net(emb_matrix=np.zeros((1000,300)), hidden_size=70)\n",
    "\n",
    "y = m(x)\n",
    "\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission1 = test_df[['qid']].copy()\n",
    "submission1.head()\n",
    "\n",
    "submission2 = pd.read_csv('../input/sample_submission.csv')\n",
    "submission2.head()\n",
    "\n",
    "all(submission1[['qid']] == submission2[['qid']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
