2019-04-22 15:46:20 Read csvs...
2019-04-22 15:46:24 Clean DataFrames...
2019-04-22 15:47:35 Tokenize...
2019-04-22 15:48:06 Pad...
2019-04-22 15:48:53 Embedding matrices
2019-04-22 15:52:17 ->loaded glove
2019-04-22 15:54:57 ->loaded paragram
2019-04-22 15:54:58 
Starting train loop

2019-04-22 15:55:03 Fold 1; num_batches = 2041
2019-04-22 15:55:03 Epoch 1/8; lr = [0.001]
2019-04-22 15:55:24 ->loss: | 72.48317389935255
2019-04-22 15:55:44 ->loss: | 62.30829003453255
2019-04-22 15:56:05 ->loss: | 59.58397292718291
2019-04-22 15:56:25 Cross-validation
2019-04-22 15:56:34 

summary: Fold 1/5 	 Epoch 1/8 	 loss=63.2638 	 val_loss=53.7697 	 time=91.21s

2019-04-22 15:56:34 Epoch 2/8; lr = [0.001]
2019-04-22 15:56:55 ->loss: | 56.96389031410217
2019-04-22 15:57:15 ->loss: | 56.43201723694801
2019-04-22 15:57:36 ->loss: | 56.096767734736204
2019-04-22 15:57:57 Cross-validation
2019-04-22 15:58:05 

summary: Fold 1/5 	 Epoch 2/8 	 loss=56.2799 	 val_loss=52.6777 	 time=91.18s

2019-04-22 15:58:05 Epoch 3/8; lr = [0.001]
2019-04-22 15:58:26 ->loss: | 53.35252317041159
2019-04-22 15:58:47 ->loss: | 53.67217869311571
2019-04-22 15:59:07 ->loss: | 54.17468960955739
2019-04-22 15:59:28 Cross-validation
2019-04-22 15:59:36 

summary: Fold 1/5 	 Epoch 3/8 	 loss=53.6739 	 val_loss=50.8334 	 time=91.20s

2019-04-22 15:59:36 Epoch 4/8; lr = [0.0005]
2019-04-22 15:59:57 ->loss: | 50.5638618580997
2019-04-22 16:00:18 ->loss: | 51.42201970145106
2019-04-22 16:00:38 ->loss: | 50.52778164297342
2019-04-22 16:00:59 Cross-validation
2019-04-22 16:01:07 

summary: Fold 1/5 	 Epoch 4/8 	 loss=50.9028 	 val_loss=49.8811 	 time=91.18s

2019-04-22 16:01:07 Epoch 5/8; lr = [0.0005]
2019-04-22 16:01:28 ->loss: | 49.862895879894495
2019-04-22 16:01:49 ->loss: | 49.47497547417879
2019-04-22 16:02:10 ->loss: | 49.39378219842911
2019-04-22 16:02:30 Cross-validation
2019-04-22 16:02:39 

summary: Fold 1/5 	 Epoch 5/8 	 loss=49.5847 	 val_loss=49.5812 	 time=91.34s

2019-04-22 16:02:39 Epoch 6/8; lr = [0.0005]
2019-04-22 16:03:00 ->loss: | 47.503230068832636
2019-04-22 16:03:21 ->loss: | 48.31915866211057
2019-04-22 16:03:41 ->loss: | 47.98838070780039
2019-04-22 16:04:02 Cross-validation
2019-04-22 16:04:11 

summary: Fold 1/5 	 Epoch 6/8 	 loss=48.0737 	 val_loss=50.1725 	 time=91.84s

2019-04-22 16:04:11 Epoch 7/8; lr = [0.00025]
2019-04-22 16:04:31 ->loss: | 46.15484904870391
2019-04-22 16:04:52 ->loss: | 45.94562887400389
2019-04-22 16:05:13 ->loss: | 46.441845282912254
2019-04-22 16:05:34 Cross-validation
2019-04-22 16:05:42 

summary: Fold 1/5 	 Epoch 7/8 	 loss=46.0810 	 val_loss=49.8631 	 time=91.59s

2019-04-22 16:05:42 Epoch 8/8; lr = [0.00025]
2019-04-22 16:06:03 ->loss: | 45.35197180509567
2019-04-22 16:06:24 ->loss: | 45.051309790462255
2019-04-22 16:06:45 ->loss: | 45.78364450111985
2019-04-22 16:07:05 Cross-validation
2019-04-22 16:07:14 

summary: Fold 1/5 	 Epoch 8/8 	 loss=45.4800 	 val_loss=50.6457 	 time=91.40s

2019-04-22 16:07:14 Fold 1 done; test on test data
2019-04-22 16:07:27 Fold 2; num_batches = 2041
2019-04-22 16:07:27 Epoch 1/8; lr = [0.001]
2019-04-22 16:07:47 ->loss: | 73.7060179039836
2019-04-22 16:08:08 ->loss: | 61.486623995006084
2019-04-22 16:08:29 ->loss: | 60.881815887987614
2019-04-22 16:08:49 Cross-validation
2019-04-22 16:08:58 

summary: Fold 2/5 	 Epoch 1/8 	 loss=63.6825 	 val_loss=54.4868 	 time=91.39s

2019-04-22 16:08:58 Epoch 2/8; lr = [0.001]
2019-04-22 16:09:19 ->loss: | 56.17295674234629
2019-04-22 16:09:39 ->loss: | 57.12273667752743
2019-04-22 16:10:00 ->loss: | 55.66628658026457
2019-04-22 16:10:21 Cross-validation
2019-04-22 16:10:29 

summary: Fold 2/5 	 Epoch 2/8 	 loss=56.2274 	 val_loss=52.7110 	 time=91.16s

2019-04-22 16:10:29 Epoch 3/8; lr = [0.001]
2019-04-22 16:10:50 ->loss: | 53.74461394920945
2019-04-22 16:11:11 ->loss: | 54.32978480681777
2019-04-22 16:11:31 ->loss: | 53.77700847759843
2019-04-22 16:11:52 Cross-validation
2019-04-22 16:12:00 

summary: Fold 2/5 	 Epoch 3/8 	 loss=53.7769 	 val_loss=50.9196 	 time=91.12s

2019-04-22 16:12:00 Epoch 4/8; lr = [0.0005]
2019-04-22 16:12:21 ->loss: | 50.387322556227446
2019-04-22 16:12:42 ->loss: | 50.77037534862757
2019-04-22 16:13:03 ->loss: | 50.77913010492921
2019-04-22 16:13:23 Cross-validation
2019-04-22 16:13:32 

summary: Fold 2/5 	 Epoch 4/8 	 loss=50.6213 	 val_loss=50.9258 	 time=91.37s

2019-04-22 16:13:32 Epoch 5/8; lr = [0.0005]
2019-04-22 16:13:52 ->loss: | 49.06161056086421
2019-04-22 16:14:13 ->loss: | 49.485170129686594
2019-04-22 16:14:34 ->loss: | 49.936521250754595
2019-04-22 16:14:54 Cross-validation
2019-04-22 16:15:03 

summary: Fold 2/5 	 Epoch 5/8 	 loss=49.4587 	 val_loss=50.1428 	 time=91.21s

2019-04-22 16:15:03 Epoch 6/8; lr = [0.0005]
2019-04-22 16:15:24 ->loss: | 47.800424825400114
2019-04-22 16:15:45 ->loss: | 48.3522279150784
2019-04-22 16:16:06 ->loss: | 47.99128180369735
2019-04-22 16:16:26 Cross-validation
2019-04-22 16:16:35 

summary: Fold 2/5 	 Epoch 6/8 	 loss=48.0688 	 val_loss=49.7089 	 time=91.68s

2019-04-22 16:16:35 Epoch 7/8; lr = [0.00025]
2019-04-22 16:16:55 ->loss: | 46.51533566042781
2019-04-22 16:17:16 ->loss: | 45.75769407302141
2019-04-22 16:17:37 ->loss: | 46.71905402839184
2019-04-22 16:17:58 Cross-validation
2019-04-22 16:18:06 

summary: Fold 2/5 	 Epoch 7/8 	 loss=46.3147 	 val_loss=50.0289 	 time=91.76s

2019-04-22 16:18:06 Epoch 8/8; lr = [0.00025]
2019-04-22 16:18:27 ->loss: | 45.412824250757694
2019-04-22 16:18:48 ->loss: | 45.100235641002655
2019-04-22 16:19:09 ->loss: | 45.197320420295
2019-04-22 16:19:29 Cross-validation
2019-04-22 16:19:38 

summary: Fold 2/5 	 Epoch 8/8 	 loss=45.2682 	 val_loss=50.3033 	 time=91.26s

2019-04-22 16:19:38 Fold 2 done; test on test data
2019-04-22 16:19:50 Fold 3; num_batches = 2041
2019-04-22 16:19:50 Epoch 1/8; lr = [0.001]
2019-04-22 16:20:11 ->loss: | 73.26046402007341
2019-04-22 16:20:32 ->loss: | 61.314109683036804
2019-04-22 16:20:52 ->loss: | 60.10365904122591
2019-04-22 16:21:13 Cross-validation
2019-04-22 16:21:21 

summary: Fold 3/5 	 Epoch 1/8 	 loss=63.5095 	 val_loss=54.7934 	 time=90.81s

2019-04-22 16:21:21 Epoch 2/8; lr = [0.001]
2019-04-22 16:21:42 ->loss: | 56.67990289255977
2019-04-22 16:22:03 ->loss: | 56.62327668070793
2019-04-22 16:22:23 ->loss: | 56.45266041904688
2019-04-22 16:22:44 Cross-validation
2019-04-22 16:22:52 

summary: Fold 3/5 	 Epoch 2/8 	 loss=56.3039 	 val_loss=52.3237 	 time=91.03s

2019-04-22 16:22:52 Epoch 3/8; lr = [0.001]
2019-04-22 16:23:13 ->loss: | 53.49330822005868
2019-04-22 16:23:34 ->loss: | 53.75325446203351
2019-04-22 16:23:54 ->loss: | 53.628849271684885
2019-04-22 16:24:15 Cross-validation
2019-04-22 16:24:23 

summary: Fold 3/5 	 Epoch 3/8 	 loss=53.6516 	 val_loss=51.5221 	 time=91.15s

2019-04-22 16:24:23 Epoch 4/8; lr = [0.0005]
2019-04-22 16:24:44 ->loss: | 50.43639709800482
2019-04-22 16:25:05 ->loss: | 50.88174796849489
2019-04-22 16:25:25 ->loss: | 50.65918052941561
2019-04-22 16:25:46 Cross-validation
2019-04-22 16:25:54 

summary: Fold 3/5 	 Epoch 4/8 	 loss=50.7121 	 val_loss=50.2327 	 time=90.82s

2019-04-22 16:25:54 Epoch 5/8; lr = [0.0005]
2019-04-22 16:26:15 ->loss: | 49.52124963700771
2019-04-22 16:26:35 ->loss: | 49.74873562157154
2019-04-22 16:26:55 ->loss: | 48.85265578329563
2019-04-22 16:27:15 Cross-validation
2019-04-22 16:27:23 

summary: Fold 3/5 	 Epoch 5/8 	 loss=49.3391 	 val_loss=49.9736 	 time=89.19s

2019-04-22 16:27:23 Epoch 6/8; lr = [0.0005]
2019-04-22 16:27:44 ->loss: | 47.52372833713889
2019-04-22 16:28:04 ->loss: | 47.91272281482816
2019-04-22 16:28:24 ->loss: | 48.41746189817786
2019-04-22 16:28:44 Cross-validation
2019-04-22 16:28:53 

summary: Fold 3/5 	 Epoch 6/8 	 loss=48.0396 	 val_loss=50.0954 	 time=89.18s

2019-04-22 16:28:53 Epoch 7/8; lr = [0.00025]
2019-04-22 16:29:13 ->loss: | 45.922615833580494
2019-04-22 16:29:33 ->loss: | 46.27991669252515
2019-04-22 16:29:53 ->loss: | 46.41077118366957
2019-04-22 16:30:13 Cross-validation
2019-04-22 16:30:21 

summary: Fold 3/5 	 Epoch 7/8 	 loss=46.0951 	 val_loss=50.5343 	 time=88.78s

2019-04-22 16:30:21 Epoch 8/8; lr = [0.00025]
2019-04-22 16:30:42 ->loss: | 45.40267172828317
2019-04-22 16:31:02 ->loss: | 45.47394761815667
2019-04-22 16:31:22 ->loss: | 45.81196007505059
2019-04-22 16:31:42 Cross-validation
2019-04-22 16:31:50 

summary: Fold 3/5 	 Epoch 8/8 	 loss=45.4510 	 val_loss=50.6524 	 time=88.92s

2019-04-22 16:31:50 Fold 3 done; test on test data
2019-04-22 16:32:03 Fold 4; num_batches = 2041
2019-04-22 16:32:03 Epoch 1/8; lr = [0.001]
2019-04-22 16:32:23 ->loss: | 72.89935527741909
2019-04-22 16:32:44 ->loss: | 61.29636063426733
2019-04-22 16:33:04 ->loss: | 59.93666511029005
2019-04-22 16:33:24 Cross-validation
2019-04-22 16:33:32 

summary: Fold 4/5 	 Epoch 1/8 	 loss=63.2048 	 val_loss=53.6979 	 time=89.09s

2019-04-22 16:33:32 Epoch 2/8; lr = [0.001]
2019-04-22 16:33:52 ->loss: | 57.0300739556551
2019-04-22 16:34:13 ->loss: | 56.30352495610714
2019-04-22 16:34:33 ->loss: | 55.705232601612806
2019-04-22 16:34:53 Cross-validation
2019-04-22 16:35:02 

summary: Fold 4/5 	 Epoch 2/8 	 loss=56.1324 	 val_loss=51.3925 	 time=89.50s

2019-04-22 16:35:02 Epoch 3/8; lr = [0.001]
2019-04-22 16:35:22 ->loss: | 53.17332970350981
2019-04-22 16:35:43 ->loss: | 53.99906151741743
2019-04-22 16:36:03 ->loss: | 53.475242368876934
2019-04-22 16:36:23 Cross-validation
2019-04-22 16:36:32 

summary: Fold 4/5 	 Epoch 3/8 	 loss=53.4939 	 val_loss=50.8981 	 time=89.93s

2019-04-22 16:36:32 Epoch 4/8; lr = [0.0005]
2019-04-22 16:36:52 ->loss: | 50.433328714221716
2019-04-22 16:37:12 ->loss: | 50.81705413386226
2019-04-22 16:37:32 ->loss: | 50.53795754164457
2019-04-22 16:37:52 Cross-validation
2019-04-22 16:38:01 

summary: Fold 4/5 	 Epoch 4/8 	 loss=50.5880 	 val_loss=49.9544 	 time=89.28s

2019-04-22 16:38:01 Epoch 5/8; lr = [0.0005]
2019-04-22 16:38:21 ->loss: | 49.071793753653765
2019-04-22 16:38:41 ->loss: | 49.5651048719883
2019-04-22 16:39:01 ->loss: | 49.791785176843405
2019-04-22 16:39:21 Cross-validation
2019-04-22 16:39:30 

summary: Fold 4/5 	 Epoch 5/8 	 loss=49.2564 	 val_loss=50.0623 	 time=88.66s

2019-04-22 16:39:30 Epoch 6/8; lr = [0.0005]
2019-04-22 16:39:50 ->loss: | 47.30271877348423
2019-04-22 16:40:10 ->loss: | 48.25537558272481
2019-04-22 16:40:31 ->loss: | 48.4669528901577
2019-04-22 16:40:51 Cross-validation
2019-04-22 16:40:59 

summary: Fold 4/5 	 Epoch 6/8 	 loss=48.0320 	 val_loss=49.8956 	 time=89.87s

2019-04-22 16:40:59 Epoch 7/8; lr = [0.00025]
2019-04-22 16:41:20 ->loss: | 45.84110474586487
2019-04-22 16:41:40 ->loss: | 46.32574823126197
2019-04-22 16:42:01 ->loss: | 46.36342907324433
2019-04-22 16:42:21 Cross-validation
2019-04-22 16:42:29 

summary: Fold 4/5 	 Epoch 7/8 	 loss=46.1168 	 val_loss=50.7175 	 time=89.64s

2019-04-22 16:42:29 Epoch 8/8; lr = [0.00025]
2019-04-22 16:42:49 ->loss: | 44.43578223511577
2019-04-22 16:43:10 ->loss: | 45.07337826862931
2019-04-22 16:43:30 ->loss: | 45.565417278558016
2019-04-22 16:43:50 Cross-validation
2019-04-22 16:43:58 

summary: Fold 4/5 	 Epoch 8/8 	 loss=45.0646 	 val_loss=50.9351 	 time=89.42s

2019-04-22 16:43:58 Fold 4 done; test on test data
2019-04-22 16:44:11 Fold 5; num_batches = 2041
2019-04-22 16:44:11 Epoch 1/8; lr = [0.001]
2019-04-22 16:44:31 ->loss: | 72.44301959872246
2019-04-22 16:44:52 ->loss: | 60.78161894530058
2019-04-22 16:45:12 ->loss: | 60.10681829601526
2019-04-22 16:45:32 Cross-validation
2019-04-22 16:45:40 

summary: Fold 5/5 	 Epoch 1/8 	 loss=63.0311 	 val_loss=53.3494 	 time=89.22s

2019-04-22 16:45:40 Epoch 2/8; lr = [0.001]
2019-04-22 16:46:01 ->loss: | 57.31739015132189
2019-04-22 16:46:21 ->loss: | 55.5773074477911
2019-04-22 16:46:41 ->loss: | 56.459434531629086
2019-04-22 16:47:01 Cross-validation
2019-04-22 16:47:10 

summary: Fold 5/5 	 Epoch 2/8 	 loss=56.0923 	 val_loss=51.6224 	 time=89.37s

2019-04-22 16:47:10 Epoch 3/8; lr = [0.001]
2019-04-22 16:47:30 ->loss: | 53.70407388731837
2019-04-22 16:47:50 ->loss: | 53.79907350987196
2019-04-22 16:48:11 ->loss: | 53.1090785600245
2019-04-22 16:48:31 Cross-validation
2019-04-22 16:48:39 

summary: Fold 5/5 	 Epoch 3/8 	 loss=53.5688 	 val_loss=50.9273 	 time=89.54s

2019-04-22 16:48:39 Epoch 4/8; lr = [0.0005]
2019-04-22 16:49:00 ->loss: | 51.051803573966026
2019-04-22 16:49:20 ->loss: | 50.76652089506388
2019-04-22 16:49:40 ->loss: | 50.565878197550774
2019-04-22 16:50:00 Cross-validation
2019-04-22 16:50:08 

summary: Fold 5/5 	 Epoch 4/8 	 loss=50.5777 	 val_loss=49.8399 	 time=89.17s

2019-04-22 16:50:08 Epoch 5/8; lr = [0.0005]
2019-04-22 16:50:29 ->loss: | 48.98412911966443
2019-04-22 16:50:49 ->loss: | 49.313886284828186
2019-04-22 16:51:10 ->loss: | 48.74098597466946
2019-04-22 16:51:30 Cross-validation
2019-04-22 16:51:38 

summary: Fold 5/5 	 Epoch 5/8 	 loss=49.1587 	 val_loss=50.4483 	 time=89.58s

2019-04-22 16:51:38 Epoch 6/8; lr = [0.0005]
2019-04-22 16:51:58 ->loss: | 47.28010344132781
2019-04-22 16:52:18 ->loss: | 47.76715564727783
2019-04-22 16:52:39 ->loss: | 48.04048893600702
2019-04-22 16:52:59 Cross-validation
2019-04-22 16:53:07 

summary: Fold 5/5 	 Epoch 6/8 	 loss=47.9218 	 val_loss=50.0654 	 time=89.09s

2019-04-22 16:53:07 Epoch 7/8; lr = [0.00025]
2019-04-22 16:53:27 ->loss: | 46.52714125439525
2019-04-22 16:53:48 ->loss: | 45.646845284849405
2019-04-22 16:54:08 ->loss: | 45.61312837526202
2019-04-22 16:54:28 Cross-validation
2019-04-22 16:54:36 

summary: Fold 5/5 	 Epoch 7/8 	 loss=45.9939 	 val_loss=50.3859 	 time=88.80s

2019-04-22 16:54:36 Epoch 8/8; lr = [0.00025]
2019-04-22 16:54:56 ->loss: | 44.23432222381234
2019-04-22 16:55:16 ->loss: | 44.500383857637644
2019-04-22 16:55:37 ->loss: | 46.22067900747061
2019-04-22 16:55:57 Cross-validation
2019-04-22 16:56:05 

summary: Fold 5/5 	 Epoch 8/8 	 loss=45.0550 	 val_loss=50.4952 	 time=89.33s

2019-04-22 16:56:05 Fold 5 done; test on test data
2019-04-22 16:56:16 Training done
2019-04-22 16:56:16 Finding threshold
2019-04-22 16:56:37 {'threshold': 0.3787878787878789, 'f1': 0.6814666566406182}
2019-04-22 16:56:37 Generating submission.csv
