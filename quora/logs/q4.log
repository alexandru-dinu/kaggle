Using TensorFlow backend.
Read csv
Clean DataFrames
Tokenize
Pad
Embedding matrices
	loaded glove
	loaded paragram
Starting train loop
Fold 1; num_batches = 4082
Epoch 1/8; lr = [0.001]
loss: 39.14760917983949
loss: 30.16289852000773
loss: 29.573827581480145
loss: 28.789724200963974
loss: 28.12432116828859
loss: 27.45997135527432
loss: 26.907028829678893
Cross-validation
summary: Fold 1/5 	 Epoch 1/8 	 loss=29.6561 	 val_loss=26.5210 	 time=64.85s
Epoch 2/8; lr = [0.001]
loss: 26.359799539670348
loss: 26.667879885062575
loss: 26.328268013894558
loss: 25.785361532121897
loss: 25.550181727856398
loss: 25.488687846809626
loss: 25.87136049568653
Cross-validation
summary: Fold 1/5 	 Epoch 2/8 	 loss=25.9546 	 val_loss=25.5658 	 time=66.54s
Epoch 3/8; lr = [0.0005]
loss: 24.065555181354284
loss: 23.88525038957596
loss: 24.200261617079377
loss: 24.24528751336038
loss: 24.46085318736732
loss: 24.218931145966053
loss: 24.412768812850118
Cross-validation
summary: Fold 1/5 	 Epoch 3/8 	 loss=24.1579 	 val_loss=25.1295 	 time=65.58s
Epoch 4/8; lr = [0.0005]
loss: 22.71871111728251
loss: 23.235555624589324
loss: 23.68029786273837
loss: 23.798460876569152
loss: 23.20357064343989
loss: 23.268121080473065
loss: 22.749956730753183
Cross-validation
summary: Fold 1/5 	 Epoch 4/8 	 loss=23.2403 	 val_loss=25.6393 	 time=66.14s
Epoch 5/8; lr = [0.00025]
loss: 21.864278338849545
loss: 21.844906190410256
loss: 21.8793575335294
loss: 22.41810581833124
loss: 21.941483991220593
loss: 22.02456790395081
loss: 22.276609122753143
Cross-validation
summary: Fold 1/5 	 Epoch 5/8 	 loss=22.0644 	 val_loss=25.3637 	 time=65.91s
Epoch 6/8; lr = [0.00025]
loss: 21.529392913915217
loss: 21.91836117208004
loss: 21.326623188331723
loss: 21.35228005051613
loss: 21.853308252990246
loss: 20.979544896632433
loss: 21.484784035012126
Cross-validation
summary: Fold 1/5 	 Epoch 6/8 	 loss=21.5037 	 val_loss=25.6146 	 time=65.58s
Epoch 7/8; lr = [0.000125]
loss: 20.39544977247715
loss: 20.802802180871367
loss: 20.653581514954567
loss: 20.800860276445746
loss: 21.2006084471941
loss: 20.837933342903852
loss: 20.566350892186165
Cross-validation
summary: Fold 1/5 	 Epoch 7/8 	 loss=20.7587 	 val_loss=25.8887 	 time=66.07s
Epoch 8/8; lr = [0.000125]
loss: 20.505696214735508
loss: 19.941080324351788
loss: 20.61821334809065
loss: 20.33992051333189
loss: 20.667437508702278
loss: 20.48348138295114
loss: 20.284302888438106
Cross-validation
summary: Fold 1/5 	 Epoch 8/8 	 loss=20.4312 	 val_loss=26.2503 	 time=65.63s
Fold 1 done; test on test data
Fold 2; num_batches = 4082
Epoch 1/8; lr = [0.001]
loss: 40.06207758747041
loss: 30.743986139073968
loss: 29.127793380990624
loss: 28.078280325978994
loss: 27.593570943921804
loss: 27.34652124159038
loss: 27.72510057501495
Cross-validation
summary: Fold 2/5 	 Epoch 1/8 	 loss=29.7375 	 val_loss=26.8946 	 time=65.95s
Epoch 2/8; lr = [0.001]
loss: 26.370827859267592
loss: 25.795273005962372
loss: 26.416355269029737
loss: 25.85307223163545
loss: 26.249977488070726
loss: 25.884055625647306
loss: 25.131253832951188
Cross-validation
summary: Fold 2/5 	 Epoch 2/8 	 loss=25.8539 	 val_loss=25.8848 	 time=66.97s
Epoch 3/8; lr = [0.0005]
loss: 24.008835365995765
loss: 24.1444338131696
loss: 23.78020576760173
loss: 24.210045149549842
loss: 24.149444879963994
loss: 23.648234579712152
loss: 23.7200508993119
Cross-validation
summary: Fold 2/5 	 Epoch 3/8 	 loss=23.9573 	 val_loss=25.5346 	 time=64.75s
Epoch 4/8; lr = [0.0005]
loss: 22.145616797730327
loss: 23.27910104766488
loss: 23.09200999699533
loss: 22.714793594554067
loss: 23.56827017478645
loss: 23.132546585053205
loss: 23.08777628839016
Cross-validation
summary: Fold 2/5 	 Epoch 4/8 	 loss=23.0021 	 val_loss=25.5491 	 time=59.30s
Epoch 5/8; lr = [0.00025]
loss: 22.05183306708932
loss: 21.79128455929458
loss: 21.54981631692499
loss: 21.804370967671275
loss: 21.590725706890225
loss: 21.989814711734653
loss: 21.557780915871263
Cross-validation
summary: Fold 2/5 	 Epoch 5/8 	 loss=21.7722 	 val_loss=25.8999 	 time=66.16s
Epoch 6/8; lr = [0.00025]
loss: 21.041704460978508
loss: 21.37401330843568
loss: 21.296475555747747
loss: 20.826748862862587
loss: 20.987157803028822
loss: 21.51972254924476
loss: 21.316211011260748
Cross-validation
summary: Fold 2/5 	 Epoch 6/8 	 loss=21.1708 	 val_loss=26.2068 	 time=67.41s
Epoch 7/8; lr = [0.000125]
loss: 20.04278849810362
loss: 20.336236108094454
loss: 20.4227815810591
loss: 20.476746825501323
loss: 20.72882770281285
loss: 20.839219952002168
loss: 19.996223341673613
Cross-validation
summary: Fold 2/5 	 Epoch 7/8 	 loss=20.3851 	 val_loss=26.9063 	 time=65.72s
Epoch 8/8; lr = [0.000125]
loss: 20.05257250741124
loss: 20.309280129149556
loss: 19.679827054962516
loss: 19.834933122619987
loss: 19.98029873147607
loss: 20.108100006356835
loss: 20.316973549313843
Cross-validation
summary: Fold 2/5 	 Epoch 8/8 	 loss=20.0566 	 val_loss=27.0275 	 time=64.71s
Fold 2 done; test on test data
Fold 3; num_batches = 4082
Epoch 1/8; lr = [0.001]
loss: 39.63842832483351
loss: 29.644639445468783
loss: 29.162998363375664
loss: 28.37995688803494
loss: 27.746934244409204
loss: 27.882898489013314
loss: 27.70871513709426
Cross-validation
summary: Fold 3/5 	 Epoch 1/8 	 loss=29.6134 	 val_loss=26.8887 	 time=66.59s
Epoch 2/8; lr = [0.001]
loss: 25.625146673992276
loss: 26.122648833319545
loss: 26.028993241488934
loss: 25.942356266081333
loss: 25.75955056771636
loss: 25.718412082642317
loss: 25.741825588047504
Cross-validation
summary: Fold 3/5 	 Epoch 2/8 	 loss=25.8085 	 val_loss=25.8454 	 time=66.39s
Epoch 3/8; lr = [0.0005]
loss: 24.10709718056023
loss: 23.962448174133897
loss: 23.92662658728659
loss: 24.15752130188048
loss: 24.190665420144796
loss: 23.40167232044041
loss: 24.128004025667906
Cross-validation
summary: Fold 3/5 	 Epoch 3/8 	 loss=23.8870 	 val_loss=25.7274 	 time=65.63s
Epoch 4/8; lr = [0.0005]
loss: 22.652250295504928
loss: 22.527316430583596
loss: 23.043965332210064
loss: 22.84103763848543
loss: 23.14375499635935
loss: 23.18829312361777
loss: 23.051330415531993
Cross-validation
summary: Fold 3/5 	 Epoch 4/8 	 loss=22.9181 	 val_loss=25.6568 	 time=66.58s
Epoch 5/8; lr = [0.00025]
loss: 21.556678660213947
loss: 21.721413182094693
loss: 21.50419278629124
loss: 21.55121531523764
loss: 21.338771410286427
loss: 21.8337628133595
loss: 21.847455125302076
Cross-validation
summary: Fold 3/5 	 Epoch 5/8 	 loss=21.6806 	 val_loss=25.8845 	 time=65.21s
Epoch 6/8; lr = [0.00025]
loss: 20.878021374344826
loss: 21.226447686553
loss: 20.823319503106177
loss: 21.032299522310495
loss: 20.92862263508141
loss: 21.18011293374002
loss: 21.54441041033715
Cross-validation
summary: Fold 3/5 	 Epoch 6/8 	 loss=21.0775 	 val_loss=26.3873 	 time=66.11s
Epoch 7/8; lr = [0.000125]
loss: 20.387592002749443
loss: 20.394928048364818
loss: 20.51273654215038
loss: 20.20092317648232
loss: 20.18987992219627
loss: 20.104659225791693
loss: 20.303426477126777
Cross-validation
summary: Fold 3/5 	 Epoch 7/8 	 loss=20.2788 	 val_loss=26.6697 	 time=67.49s
Epoch 8/8; lr = [0.000125]
loss: 19.668053276836872
loss: 20.013680262491107
loss: 20.44284520484507
loss: 19.855465106666088
loss: 19.518237087875605
loss: 20.04221650213003
loss: 20.023331998847425
Cross-validation
summary: Fold 3/5 	 Epoch 8/8 	 loss=19.9349 	 val_loss=26.8727 	 time=65.17s
Fold 3 done; test on test data
Fold 4; num_batches = 4082
Epoch 1/8; lr = [0.001]
loss: 38.7443026676774
loss: 29.687322491779923
loss: 28.6115435436368
loss: 28.73971844278276
loss: 28.073421575129032
loss: 27.735110856592655
loss: 26.79060554690659
Cross-validation
summary: Fold 4/5 	 Epoch 1/8 	 loss=29.4589 	 val_loss=26.6861 	 time=65.90s
Epoch 2/8; lr = [0.001]
loss: 26.158131198957562
loss: 26.136690510436893
loss: 26.288802471011877
loss: 25.241688054054976
loss: 25.293851217254996
loss: 25.738921044394374
loss: 25.47064202465117
Cross-validation
summary: Fold 4/5 	 Epoch 2/8 	 loss=25.7154 	 val_loss=25.5791 	 time=66.01s
Epoch 3/8; lr = [0.0005]
loss: 23.592437118291855
loss: 23.94235273450613
loss: 23.705985452979803
loss: 23.951165784150362
loss: 23.61670621857047
loss: 23.949711291119456
loss: 23.84746148250997
Cross-validation
summary: Fold 4/5 	 Epoch 3/8 	 loss=23.7847 	 val_loss=25.3876 	 time=63.36s
Epoch 4/8; lr = [0.0005]
loss: 22.844380650669336
loss: 22.77155014500022
loss: 22.909715643152595
loss: 22.609437953680754
loss: 22.82790875993669
loss: 23.12891543097794
loss: 22.44464100152254
Cross-validation
summary: Fold 4/5 	 Epoch 4/8 	 loss=22.8214 	 val_loss=25.4548 	 time=61.98s
Epoch 5/8; lr = [0.00025]
loss: 21.767796859145164
loss: 21.35496547818184
loss: 21.473034724593163
loss: 21.293342754244804
loss: 21.5095435064286
loss: 22.000101311132312
loss: 21.501258758828044
Cross-validation
summary: Fold 4/5 	 Epoch 5/8 	 loss=21.5389 	 val_loss=25.9547 	 time=63.30s
Epoch 6/8; lr = [0.00025]
loss: 20.476023200899363
loss: 20.557201387360692
loss: 20.84322690591216
loss: 20.9873282648623
loss: 21.164639631286263
loss: 21.196102717891335
loss: 21.13529911544174
Cross-validation
summary: Fold 4/5 	 Epoch 6/8 	 loss=20.9354 	 val_loss=26.0481 	 time=63.27s
Epoch 7/8; lr = [0.000125]
loss: 19.918327437713742
loss: 20.444148179143667
loss: 20.45624171756208
loss: 20.305439103394747
loss: 19.840225698426366
loss: 19.905529018491507
loss: 19.91798899974674
Cross-validation
summary: Fold 4/5 	 Epoch 7/8 	 loss=20.1050 	 val_loss=26.4384 	 time=62.64s
Epoch 8/8; lr = [0.000125]
loss: 19.837775306776166
loss: 19.237818020395935
loss: 19.83098205924034
loss: 19.756678394973278
loss: 20.135979978367686
loss: 19.59486963506788
loss: 19.68132635951042
Cross-validation
summary: Fold 4/5 	 Epoch 8/8 	 loss=19.7612 	 val_loss=26.7702 	 time=64.22s
Fold 4 done; test on test data
Fold 5; num_batches = 4082
Epoch 1/8; lr = [0.001]
loss: 38.89408067986369
loss: 29.919728063046932
loss: 29.01806380599737
loss: 27.928318738937378
loss: 27.44522256962955
loss: 28.081547558307648
loss: 27.27492548711598
Cross-validation
summary: Fold 5/5 	 Epoch 1/8 	 loss=29.4090 	 val_loss=27.2445 	 time=63.53s
Epoch 2/8; lr = [0.001]
loss: 26.146156433969736
loss: 26.11302383802831
loss: 25.815349001437426
loss: 25.308973783627152
loss: 25.849463403224945
loss: 25.48183796554804
loss: 25.687606105580926
Cross-validation
summary: Fold 5/5 	 Epoch 2/8 	 loss=25.7406 	 val_loss=26.7200 	 time=62.98s
Epoch 3/8; lr = [0.0005]
loss: 23.849948635324836
loss: 23.533638508990407
loss: 24.221506483852863
loss: 24.4191082585603
loss: 24.213093996047974
loss: 24.000841822475195
loss: 23.302543930709362
Cross-validation
summary: Fold 5/5 	 Epoch 3/8 	 loss=23.9242 	 val_loss=25.9995 	 time=62.91s
Epoch 4/8; lr = [0.0005]
loss: 23.178213937208056
loss: 22.72464019432664
loss: 23.42140549980104
loss: 23.138851407915354
loss: 22.71831689029932
loss: 23.03947377577424
loss: 22.838695812039077
Cross-validation
summary: Fold 5/5 	 Epoch 4/8 	 loss=23.0538 	 val_loss=26.0551 	 time=64.94s
Epoch 5/8; lr = [0.00025]
loss: 22.030568420886993
loss: 22.003527715802193
loss: 21.89554264768958
loss: 21.705072976648808
loss: 22.21923853456974
loss: 21.82934840582311
loss: 21.806420110166073
Cross-validation
summary: Fold 5/5 	 Epoch 5/8 	 loss=21.8883 	 val_loss=26.4996 	 time=63.16s
Epoch 6/8; lr = [0.00025]
loss: 20.98005502484739
loss: 20.97478821501136
loss: 21.705270294100046
loss: 21.20706365816295
loss: 21.481282795779407
loss: 21.504656177014112
loss: 21.576835934072733
Cross-validation
summary: Fold 5/5 	 Epoch 6/8 	 loss=21.3404 	 val_loss=26.6835 	 time=62.61s
Epoch 7/8; lr = [0.000125]
loss: 20.301211607642472
loss: 20.710037933662534
loss: 20.54291069228202
loss: 20.48181207291782
loss: 20.319339668378234
loss: 20.878053843975067
loss: 20.697947566397488
Cross-validation
summary: Fold 5/5 	 Epoch 7/8 	 loss=20.6030 	 val_loss=26.9850 	 time=63.14s
Epoch 8/8; lr = [0.000125]
loss: 19.923814612440765
loss: 20.202098733745515
loss: 20.374935098923743
loss: 20.57808344438672
loss: 20.037205005064607
loss: 20.41084285080433
loss: 20.235742965713143
Cross-validation
summary: Fold 5/5 	 Epoch 8/8 	 loss=20.2634 	 val_loss=27.2308 	 time=62.63s
Fold 5 done; test on test data
Training done
Finding threshold
{'threshold': 0.31818181818181834, 'f1': 0.6701901179747385}
Generating submission.csv
