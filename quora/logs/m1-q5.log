Using TensorFlow backend.
Read csv
Clean DataFrames
Tokenize
Pad
Embedding matrices
	loaded glove
	loaded paragram
Starting train loop
Fold 1; num_batches = 4082
Epoch 1/8; lr = [0.001]
loss: 37.26997828669846
loss: 29.18918125331402
loss: 28.660375168547034
loss: 27.839131638407707
loss: 27.711184479296207
loss: 27.49940255843103
loss: 27.022153859958053
Cross-validation
summary: Fold 1/5 	 Epoch 1/8 	 loss=29.0389 	 val_loss=25.9875 	 time=96.95s
Epoch 2/8; lr = [0.001]
loss: 25.878582432866096
loss: 25.470108665525913
loss: 25.478951022028923
loss: 25.76836606860161
loss: 24.9321735072881
loss: 24.830031728371978
loss: 24.695988157764077
Cross-validation
summary: Fold 1/5 	 Epoch 2/8 	 loss=25.1976 	 val_loss=25.2268 	 time=97.55s
Epoch 3/8; lr = [0.0005]
loss: 22.515146849676967
loss: 23.184125669300556
loss: 22.846944890916348
loss: 22.892436729744077
loss: 23.1213592980057
loss: 22.55621142499149
loss: 22.973932648077607
Cross-validation
summary: Fold 1/5 	 Epoch 3/8 	 loss=22.8751 	 val_loss=24.5337 	 time=97.70s
Epoch 4/8; lr = [0.0005]
loss: 21.35719244927168
loss: 21.75829810090363
loss: 21.30774349346757
loss: 21.535942927002907
loss: 21.845863413065672
loss: 21.439283419400454
loss: 21.616604801267385
Cross-validation
summary: Fold 1/5 	 Epoch 4/8 	 loss=21.6104 	 val_loss=24.5858 	 time=98.49s
Epoch 5/8; lr = [0.00025]
loss: 20.228752421215177
loss: 19.594992192462087
loss: 20.237462707795203
loss: 19.5024051964283
loss: 19.771240796893835
loss: 19.781509133055806
loss: 19.971552403643727
Cross-validation
summary: Fold 1/5 	 Epoch 5/8 	 loss=19.8818 	 val_loss=25.3762 	 time=98.47s
Epoch 6/8; lr = [0.00025]
loss: 18.69728226773441
loss: 18.791642172262073
loss: 19.206530090421438
loss: 19.036760937422514
loss: 19.213716227561235
loss: 18.950591176748276
loss: 19.427012518048286
Cross-validation
summary: Fold 1/5 	 Epoch 6/8 	 loss=19.0797 	 val_loss=25.8293 	 time=98.05s
Epoch 7/8; lr = [0.000125]
loss: 17.992399984039366
loss: 18.231446756981313
loss: 17.3443258786574
loss: 18.075932825915515
loss: 18.06330748926848
loss: 17.809180360287428
loss: 17.80053603835404
Cross-validation
summary: Fold 1/5 	 Epoch 7/8 	 loss=17.9315 	 val_loss=26.5514 	 time=98.45s
Epoch 8/8; lr = [0.000125]
loss: 17.144274308346212
loss: 17.23894349578768
loss: 17.634272823110223
loss: 17.287615779787302
loss: 17.564716043882072
loss: 17.554042011499405
loss: 17.715000121854246
Cross-validation
summary: Fold 1/5 	 Epoch 8/8 	 loss=17.4576 	 val_loss=27.3562 	 time=97.88s
Fold 1 done; test on test data
Fold 2; num_batches = 4082
Epoch 1/8; lr = [0.001]
loss: 36.76358077302575
loss: 29.936506405472755
loss: 28.839623868465424
loss: 27.896890457719564
loss: 27.591249583289027
loss: 26.710864087566733
loss: 26.587105229496956
Cross-validation
summary: Fold 2/5 	 Epoch 1/8 	 loss=28.9012 	 val_loss=26.2160 	 time=98.16s
Epoch 2/8; lr = [0.001]
loss: 25.5698317065835
loss: 25.35740383155644
loss: 25.40206042677164
loss: 25.06244240142405
loss: 25.004761246964335
loss: 25.116715831682086
loss: 24.98925120010972
Cross-validation
summary: Fold 2/5 	 Epoch 2/8 	 loss=25.1279 	 val_loss=25.2468 	 time=98.14s
Epoch 3/8; lr = [0.0005]
loss: 23.099798291921616
loss: 22.5777401458472
loss: 22.5709433760494
loss: 22.667792624793947
loss: 22.90907669439912
loss: 23.17879220843315
loss: 22.67623514123261
Cross-validation
summary: Fold 2/5 	 Epoch 3/8 	 loss=22.7784 	 val_loss=25.8326 	 time=97.98s
Epoch 4/8; lr = [0.0005]
loss: 21.230073193088174
loss: 21.53435079753399
loss: 21.77944982610643
loss: 21.417064141482115
loss: 21.721601240336895
loss: 21.326989743858576
loss: 21.70776305347681
Cross-validation
summary: Fold 2/5 	 Epoch 4/8 	 loss=21.5549 	 val_loss=25.1858 	 time=98.02s
Epoch 5/8; lr = [0.00025]
loss: 19.665432211011648
loss: 19.948685104958713
loss: 19.752250694669783
loss: 20.09974271710962
loss: 19.6296821013093
loss: 19.720359940081835
loss: 20.084391391836107
Cross-validation
summary: Fold 2/5 	 Epoch 5/8 	 loss=19.8333 	 val_loss=25.6536 	 time=98.61s
Epoch 6/8; lr = [0.00025]
loss: 18.876741407439113
loss: 18.716376604512334
loss: 18.944539402611554
loss: 18.80768151767552
loss: 18.868918735533953
loss: 19.368217507377267
loss: 19.368109388276935
Cross-validation
summary: Fold 2/5 	 Epoch 6/8 	 loss=19.0000 	 val_loss=26.1424 	 time=97.81s
Epoch 7/8; lr = [0.000125]
loss: 17.917351361364126
loss: 17.938269279897213
loss: 18.016537466086447
loss: 18.17790451645851
loss: 17.497593821026385
loss: 17.666904140263796
loss: 17.198943546041846
Cross-validation
summary: Fold 2/5 	 Epoch 7/8 	 loss=17.8558 	 val_loss=27.1138 	 time=98.19s
Epoch 8/8; lr = [0.000125]
loss: 17.124635278247297
loss: 17.112639885395765
loss: 17.37595435604453
loss: 17.060410350561142
loss: 17.279479044489563
loss: 17.24160100799054
loss: 17.880543425679207
Cross-validation
summary: Fold 2/5 	 Epoch 8/8 	 loss=17.4027 	 val_loss=27.3760 	 time=98.11s
Fold 2 done; test on test data
Fold 3; num_batches = 4082
Epoch 1/8; lr = [0.001]
loss: 37.64758212119341
loss: 29.82927232608199
loss: 28.292247930541635
loss: 28.126164715737104
loss: 27.603464679792523
loss: 27.176484463736415
loss: 27.13228423334658
Cross-validation
summary: Fold 3/5 	 Epoch 1/8 	 loss=29.0608 	 val_loss=26.0655 	 time=98.06s
Epoch 2/8; lr = [0.001]
loss: 25.26310888119042
loss: 25.301545679569244
loss: 25.241676488891244
loss: 25.20208913832903
loss: 25.356042556464672
loss: 25.174947511404753
loss: 25.100855154916644
Cross-validation
summary: Fold 3/5 	 Epoch 2/8 	 loss=25.1997 	 val_loss=25.2770 	 time=97.31s
Epoch 3/8; lr = [0.0005]
loss: 23.169513965025544
loss: 22.705353839322925
loss: 23.007056709378958
loss: 22.979703534394503
loss: 23.00836582481861
loss: 22.567131163552403
loss: 22.87071695458144
Cross-validation
summary: Fold 3/5 	 Epoch 3/8 	 loss=22.8704 	 val_loss=24.9061 	 time=96.12s
Epoch 4/8; lr = [0.0005]
loss: 21.411811572499573
loss: 20.992353732697666
loss: 21.26852623745799
loss: 21.804943551309407
loss: 21.794426342472434
loss: 21.60201303381473
loss: 21.85135085321963
Cross-validation
summary: Fold 3/5 	 Epoch 4/8 	 loss=21.5918 	 val_loss=24.8361 	 time=95.52s
Epoch 5/8; lr = [0.00025]
loss: 19.81845979578793
loss: 19.9627146711573
loss: 19.75258751772344
loss: 19.934487556107342
loss: 19.997647935524583
loss: 19.820203225128353
loss: 20.147329468280077
Cross-validation
summary: Fold 3/5 	 Epoch 5/8 	 loss=19.9238 	 val_loss=25.4817 	 time=95.55s
Epoch 6/8; lr = [0.00025]
loss: 18.56931744515896
loss: 18.950291560962796
loss: 18.949397680349648
loss: 18.941618380136788
loss: 19.61174407787621
loss: 19.85017280559987
loss: 18.939775308594108
Cross-validation
summary: Fold 3/5 	 Epoch 6/8 	 loss=19.0932 	 val_loss=25.9719 	 time=96.08s
Epoch 7/8; lr = [0.000125]
loss: 17.5620990768075
loss: 18.091786078177392
loss: 18.07396877463907
loss: 17.840655367821455
loss: 18.123598784208298
loss: 17.924718865193427
loss: 18.220782513730228
Cross-validation
summary: Fold 3/5 	 Epoch 7/8 	 loss=18.0050 	 val_loss=26.5778 	 time=95.39s
Epoch 8/8; lr = [0.000125]
loss: 17.365732333622873
loss: 17.45948244445026
loss: 17.267640012316406
loss: 17.47787267062813
loss: 17.340145470574498
loss: 17.321577733382583
loss: 17.68649139162153
Cross-validation
summary: Fold 3/5 	 Epoch 8/8 	 loss=17.5089 	 val_loss=26.8558 	 time=95.74s
Fold 3 done; test on test data
Fold 4; num_batches = 4082
Epoch 1/8; lr = [0.001]
loss: 37.55327387340367
loss: 29.785328153520823
loss: 28.736382510513067
loss: 28.0825302824378
loss: 26.815364833921194
loss: 27.218114890158176
loss: 26.776515489444137
Cross-validation
summary: Fold 4/5 	 Epoch 1/8 	 loss=28.9314 	 val_loss=26.9954 	 time=95.74s
Epoch 2/8; lr = [0.001]
loss: 25.413881139829755
loss: 25.500356294214725
loss: 25.605346903204918
loss: 25.302714774385095
loss: 25.15682161785662
loss: 25.153121285140514
loss: 24.276054272428155
Cross-validation
summary: Fold 4/5 	 Epoch 2/8 	 loss=25.1306 	 val_loss=25.6111 	 time=95.13s
Epoch 3/8; lr = [0.0005]
loss: 23.073007789440453
loss: 23.01649739779532
loss: 22.481661219149828
loss: 22.517152872867882
loss: 23.159794254228473
loss: 22.914559327065945
loss: 22.803730312734842
Cross-validation
summary: Fold 4/5 	 Epoch 3/8 	 loss=22.8516 	 val_loss=25.0946 	 time=95.80s
Epoch 4/8; lr = [0.0005]
loss: 20.893794337287545
loss: 21.711990488693118
loss: 21.180351732298732
loss: 21.82225003093481
loss: 21.44378294982016
loss: 22.32019306346774
loss: 21.67864722572267
Cross-validation
summary: Fold 4/5 	 Epoch 4/8 	 loss=21.6137 	 val_loss=25.3876 	 time=96.43s
Epoch 5/8; lr = [0.00025]
loss: 19.98815675638616
loss: 19.27971332333982
loss: 19.736062055453658
loss: 20.052804950624704
loss: 20.167439870536327
loss: 19.765530550852418
loss: 19.877249898388982
Cross-validation
summary: Fold 4/5 	 Epoch 5/8 	 loss=19.9177 	 val_loss=25.7845 	 time=96.89s
Epoch 6/8; lr = [0.00025]
loss: 18.660503435879946
loss: 18.894181605428457
loss: 19.060357304289937
loss: 18.75573276914656
loss: 19.040296617895365
loss: 19.255228348076344
loss: 19.746064024046063
Cross-validation
summary: Fold 4/5 	 Epoch 6/8 	 loss=19.1154 	 val_loss=26.9854 	 time=95.75s
Epoch 7/8; lr = [0.000125]
loss: 17.506311520002782
loss: 18.619358394294977
loss: 18.28990904800594
loss: 18.071738832630217
loss: 18.015048218891025
loss: 17.186124951578677
loss: 18.741094254888594
Cross-validation
summary: Fold 4/5 	 Epoch 7/8 	 loss=18.0439 	 val_loss=26.8222 	 time=96.76s
Epoch 8/8; lr = [0.000125]
loss: 17.225941526703537
loss: 17.498440522700548
loss: 17.55736577231437
loss: 17.368999052792788
loss: 17.354120296426117
loss: 17.49432502221316
loss: 17.83422341477126
Cross-validation
summary: Fold 4/5 	 Epoch 8/8 	 loss=17.5757 	 val_loss=27.2357 	 time=96.50s
Fold 4 done; test on test data
Fold 5; num_batches = 4082
Epoch 1/8; lr = [0.001]
loss: 37.57370890676975
loss: 29.820197666063905
loss: 28.261115770787
loss: 27.934679804369807
loss: 27.989648316055536
loss: 26.350194957107306
loss: 26.631679326295853
Cross-validation
summary: Fold 5/5 	 Epoch 1/8 	 loss=28.9063 	 val_loss=26.9715 	 time=95.76s
Epoch 2/8; lr = [0.001]
loss: 25.718411466106772
loss: 25.064153768122196
loss: 25.1808891762048
loss: 24.388385232537985
loss: 24.639774844050407
loss: 25.38528687506914
loss: 24.95357204414904
Cross-validation
summary: Fold 5/5 	 Epoch 2/8 	 loss=25.0461 	 val_loss=25.5747 	 time=96.39s
Epoch 3/8; lr = [0.0005]
loss: 22.58984486013651
loss: 22.84221070446074
loss: 22.810053097084165
loss: 22.766305109485984
loss: 22.457603577524424
loss: 22.773035435006022
loss: 22.495465870946646
Cross-validation
summary: Fold 5/5 	 Epoch 3/8 	 loss=22.6958 	 val_loss=25.4122 	 time=96.09s
Epoch 4/8; lr = [0.0005]
loss: 20.909068554639816
loss: 21.258915919810534
loss: 21.445350835099816
loss: 21.4644694365561
loss: 21.635578898712993
loss: 21.5020166458562
loss: 21.506460588425398
Cross-validation
summary: Fold 5/5 	 Epoch 4/8 	 loss=21.4330 	 val_loss=25.6084 	 time=95.56s
Epoch 5/8; lr = [0.00025]
loss: 19.82861304655671
loss: 19.55841679032892
loss: 19.82894716411829
loss: 19.55301058292389
loss: 19.45606471132487
loss: 19.795198116451502
loss: 19.94003438297659
Cross-validation
summary: Fold 5/5 	 Epoch 5/8 	 loss=19.7361 	 val_loss=26.1912 	 time=95.99s
Epoch 6/8; lr = [0.00025]
loss: 18.6117034945637
loss: 18.84980947431177
loss: 18.569138813763857
loss: 19.11549874022603
loss: 18.835799072869122
loss: 19.551358087919652
loss: 18.995973240584135
Cross-validation
summary: Fold 5/5 	 Epoch 6/8 	 loss=18.8976 	 val_loss=26.5263 	 time=96.57s
Epoch 7/8; lr = [0.000125]
loss: 17.29236147738993
loss: 17.9140145489946
loss: 17.577190555632114
loss: 17.305390877649188
loss: 18.064576686359942
loss: 17.903446298092604
loss: 17.798049131408334
Cross-validation
summary: Fold 5/5 	 Epoch 7/8 	 loss=17.7604 	 val_loss=27.3557 	 time=95.90s
Epoch 8/8; lr = [0.000125]
loss: 17.18393164779991
loss: 17.060498495586216
loss: 17.227777729276568
loss: 17.33462166506797
loss: 17.464382596313953
loss: 17.545466504991055
loss: 17.243324269540608
Cross-validation
summary: Fold 5/5 	 Epoch 8/8 	 loss=17.2708 	 val_loss=28.0456 	 time=96.10s
Fold 5 done; test on test data
Training done
Finding threshold
{'threshold': 0.31818181818181834, 'f1': 0.6766410660933988}
Generating submission.csv
